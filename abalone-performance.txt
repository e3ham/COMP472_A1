------------------------------------------
(A) Base-DT with default parameters
(B) Confusion Matrix:
[[143  40 146]
 [ 56 198  68]
 [139  74 181]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.42      0.43      0.43       329
           I       0.63      0.61      0.62       322
           M       0.46      0.46      0.46       394

    accuracy                           0.50      1045
   macro avg       0.51      0.50      0.50      1045
weighted avg       0.50      0.50      0.50      1045

(D) Accuracy: 0.4995215311004785
Macro Average F1 Score: 0.5040666346447588
Weighted Average F1 Score: 0.5004441041622308

------------------------------------------
(A) Top-DT with gridsearch
Parameters: criterion: [gini, entropy], max depth: [none, 10, 20], minimum sample split: [2, 4, 6]
Best parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}(B) Confusion Matrix:
[[155  60 114]
 [ 44 235  43]
 [190  73 131]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.40      0.47      0.43       329
           I       0.64      0.73      0.68       322
           M       0.45      0.33      0.38       394

    accuracy                           0.50      1045
   macro avg       0.50      0.51      0.50      1045
weighted avg       0.49      0.50      0.49      1045

(D) Accuracy: 0.49856459330143543
Macro Average F1 Score: 0.4990261726051887
Weighted Average F1 Score: 0.49066161809195763

------------------------------------------
Repeated Evaluation for DecisionTreeClassifier
Average Accuracy: 0.5190430622009569
Variance in Accuracy: 0.0002906893157207939
Average Macro F1 Score: 0.5163971173789152
Variance in Macro F1 Score: 0.00034129346535358043
Average Weighted F1 Score: 0.5151540555609458
Variance in Weighted F1 Score: 0.00041132552847098733

------------------------------------------
(A) Base-MLP with default parameters
(B) Confusion Matrix:
[[  0  54 275]
 [  0 205 117]
 [  0  69 325]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       329
           I       0.62      0.64      0.63       322
           M       0.45      0.82      0.59       394

    accuracy                           0.51      1045
   macro avg       0.36      0.49      0.41      1045
weighted avg       0.36      0.51      0.41      1045

(D) Accuracy: 0.507177033492823
Macro Average F1 Score: 0.40527591220660525
Weighted Average F1 Score: 0.4149480800122706

------------------------------------------
(A) Top-MLP with gridsearch
Parameters: activation function: [sigmoid, tanh, relu], hidden layers: [(30, 50), (10, 10, 10)], solver: [adam, sgd]
Best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}(B) Confusion Matrix:
[[145  47 137]
 [ 17 253  52]
 [168  77 149]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.44      0.44      0.44       329
           I       0.67      0.79      0.72       322
           M       0.44      0.38      0.41       394

    accuracy                           0.52      1045
   macro avg       0.52      0.53      0.52      1045
weighted avg       0.51      0.52      0.52      1045

(D) Accuracy: 0.523444976076555
Macro Average F1 Score: 0.5236852654704741
Weighted Average F1 Score: 0.5150926954454597

------------------------------------------
Repeated Evaluation for MLPClassifier
Average Accuracy: 0.5418181818181818
Variance in Accuracy: 0.00031332616011538124
Average Macro F1 Score: 0.4934906048489223
Variance in Macro F1 Score: 0.0013757809434076502
Average Weighted F1 Score: 0.4966770184170436
Variance in Weighted F1 Score: 0.00152592403860318

------------------------------------------
(A) Base-DT with default parameters
(B) Confusion Matrix:
[[150  45 154]
 [ 61 230  65]
 [141  58 141]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.43      0.43      0.43       349
           I       0.69      0.65      0.67       356
           M       0.39      0.41      0.40       340

    accuracy                           0.50      1045
   macro avg       0.50      0.50      0.50      1045
weighted avg       0.51      0.50      0.50      1045

(D) Accuracy: 0.49856459330143543
Macro Average F1 Score: 0.49948381748613224
Weighted Average F1 Score: 0.5014423754928666

------------------------------------------
(A) Top-DT with gridsearch
Parameters: criterion: [gini, entropy], max depth: [none, 10, 20], minimum sample split: [2, 4, 6]
Best parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}(B) Confusion Matrix:
[[116  49 184]
 [ 48 248  60]
 [ 82  60 198]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.47      0.33      0.39       349
           I       0.69      0.70      0.70       356
           M       0.45      0.58      0.51       340

    accuracy                           0.54      1045
   macro avg       0.54      0.54      0.53      1045
weighted avg       0.54      0.54      0.53      1045

(D) Accuracy: 0.5377990430622009
Macro Average F1 Score: 0.5306540007307271
Weighted Average F1 Score: 0.5319681906463438

------------------------------------------
Repeated Evaluation for DecisionTreeClassifier
Average Accuracy: 0.5213397129186602
Variance in Accuracy: 0.00018329250703967413
Average Macro F1 Score: 0.5183974927379791
Variance in Macro F1 Score: 0.00023670402284831915
Average Weighted F1 Score: 0.5172639904484033
Variance in Weighted F1 Score: 0.0002617981629089791

------------------------------------------
(A) Base-MLP with default parameters
(B) Confusion Matrix:
[[  0  15 334]
 [  0 182 174]
 [  0  30 310]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       349
           I       0.80      0.51      0.62       356
           M       0.38      0.91      0.54       340

    accuracy                           0.47      1045
   macro avg       0.39      0.47      0.39      1045
weighted avg       0.40      0.47      0.39      1045

(D) Accuracy: 0.47081339712918663
Macro Average F1 Score: 0.38658754916453614
Weighted Average F1 Score: 0.386898572777636

------------------------------------------
(A) Top-MLP with gridsearch
Parameters: activation function: [sigmoid, tanh, relu], hidden layers: [(30, 50), (10, 10, 10)], solver: [adam, sgd]
Best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}(B) Confusion Matrix:
[[ 47  57 245]
 [  6 305  45]
 [ 37  75 228]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.52      0.13      0.21       349
           I       0.70      0.86      0.77       356
           M       0.44      0.67      0.53       340

    accuracy                           0.56      1045
   macro avg       0.55      0.55      0.50      1045
weighted avg       0.56      0.56      0.51      1045

(D) Accuracy: 0.5550239234449761
Macro Average F1 Score: 0.5049407691776713
Weighted Average F1 Score: 0.5064826640482492

------------------------------------------
Repeated Evaluation for MLPClassifier
Average Accuracy: 0.543732057416268
Variance in Accuracy: 0.0001572857764245324
Average Macro F1 Score: 0.5020735404884542
Variance in Macro F1 Score: 0.0017462595281491188
Average Weighted F1 Score: 0.5030620546201432
Variance in Weighted F1 Score: 0.001816798250037224

------------------------------------------
(A) Base-DT with default parameters
(B) Confusion Matrix:
[[130  42 128]
 [ 58 209  72]
 [159  75 172]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.37      0.43      0.40       300
           I       0.64      0.62      0.63       339
           M       0.46      0.42      0.44       406

    accuracy                           0.49      1045
   macro avg       0.49      0.49      0.49      1045
weighted avg       0.50      0.49      0.49      1045

(D) Accuracy: 0.48899521531100476
Macro Average F1 Score: 0.4908618418899208
Weighted Average F1 Score: 0.4910610890112507

------------------------------------------
(A) Top-DT with gridsearch
Parameters: criterion: [gini, entropy], max depth: [none, 10, 20], minimum sample split: [2, 4, 6]
Best parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}(B) Confusion Matrix:
[[142  44 114]
 [ 32 243  64]
 [192  74 140]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.39      0.47      0.43       300
           I       0.67      0.72      0.69       339
           M       0.44      0.34      0.39       406

    accuracy                           0.50      1045
   macro avg       0.50      0.51      0.50      1045
weighted avg       0.50      0.50      0.50      1045

(D) Accuracy: 0.5023923444976076
Macro Average F1 Score: 0.5024841574012845
Weighted Average F1 Score: 0.49790177957552195

------------------------------------------
Repeated Evaluation for DecisionTreeClassifier
Average Accuracy: 0.5205741626794259
Variance in Accuracy: 0.00027801561319566856
Average Macro F1 Score: 0.5180239185945423
Variance in Macro F1 Score: 0.00033224710065595686
Average Weighted F1 Score: 0.5166572538911908
Variance in Weighted F1 Score: 0.0003914531125680255

------------------------------------------
(A) Base-MLP with default parameters
(B) Confusion Matrix:
[[ 12  32 256]
 [  1 233 105]
 [ 11  64 331]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.04      0.07       300
           I       0.71      0.69      0.70       339
           M       0.48      0.82      0.60       406

    accuracy                           0.55      1045
   macro avg       0.56      0.51      0.46      1045
weighted avg       0.56      0.55      0.48      1045

(D) Accuracy: 0.5511961722488038
Macro Average F1 Score: 0.45819775143095715
Weighted Average F1 Score: 0.4818119506535598

------------------------------------------
(A) Top-MLP with gridsearch
Parameters: activation function: [sigmoid, tanh, relu], hidden layers: [(30, 50), (10, 10, 10)], solver: [adam, sgd]
Best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}(B) Confusion Matrix:
[[153  37 110]
 [ 26 249  64]
 [185  65 156]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.42      0.51      0.46       300
           I       0.71      0.73      0.72       339
           M       0.47      0.38      0.42       406

    accuracy                           0.53      1045
   macro avg       0.53      0.54      0.54      1045
weighted avg       0.53      0.53      0.53      1045

(D) Accuracy: 0.5339712918660288
Macro Average F1 Score: 0.5354985158023399
Weighted Average F1 Score: 0.5311304047059885

------------------------------------------
Repeated Evaluation for MLPClassifier
Average Accuracy: 0.5385645933014354
Variance in Accuracy: 0.0002213868730111492
Average Macro F1 Score: 0.5044644854247358
Variance in Macro F1 Score: 0.0001581514776318523
Average Weighted F1 Score: 0.5067271531443749
Variance in Weighted F1 Score: 0.00028143138370454417

------------------------------------------
(A) Base-DT with default parameters
(B) Confusion Matrix:
[[140  56 137]
 [ 45 203  77]
 [127  77 183]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.45      0.42      0.43       333
           I       0.60      0.62      0.61       325
           M       0.46      0.47      0.47       387

    accuracy                           0.50      1045
   macro avg       0.50      0.51      0.51      1045
weighted avg       0.50      0.50      0.50      1045

(D) Accuracy: 0.5033492822966508
Macro Average F1 Score: 0.5050553797613523
Weighted Average F1 Score: 0.5022447282635342

------------------------------------------
(A) Top-DT with gridsearch
Parameters: criterion: [gini, entropy], max depth: [none, 10, 20], minimum sample split: [2, 4, 6]
Best parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 6}(B) Confusion Matrix:
[[141  59 133]
 [ 45 234  46]
 [145  88 154]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.43      0.42      0.42       333
           I       0.61      0.72      0.66       325
           M       0.46      0.40      0.43       387

    accuracy                           0.51      1045
   macro avg       0.50      0.51      0.51      1045
weighted avg       0.50      0.51      0.50      1045

(D) Accuracy: 0.5062200956937799
Macro Average F1 Score: 0.5051220304573661
Weighted Average F1 Score: 0.49991750457377976

------------------------------------------
Repeated Evaluation for DecisionTreeClassifier
Average Accuracy: 0.5198086124401914
Variance in Accuracy: 0.00024189922391886607
Average Macro F1 Score: 0.5170353297349866
Variance in Macro F1 Score: 0.0003009355929940812
Average Weighted F1 Score: 0.5157042916436698
Variance in Weighted F1 Score: 0.00034932462049952907

------------------------------------------
(A) Base-MLP with default parameters
(B) Confusion Matrix:
[[  0  42 291]
 [  0 213 112]
 [  0  76 311]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       333
           I       0.64      0.66      0.65       325
           M       0.44      0.80      0.56       387

    accuracy                           0.50      1045
   macro avg       0.36      0.49      0.40      1045
weighted avg       0.36      0.50      0.41      1045

(D) Accuracy: 0.5014354066985646
Macro Average F1 Score: 0.40477706888785514
Weighted Average F1 Score: 0.41118084388215176

------------------------------------------
(A) Top-MLP with gridsearch
Parameters: activation function: [sigmoid, tanh, relu], hidden layers: [(30, 50), (10, 10, 10)], solver: [adam, sgd]
Best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}(B) Confusion Matrix:
[[ 33  41 259]
 [  7 247  71]
 [ 22  71 294]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.53      0.10      0.17       333
           I       0.69      0.76      0.72       325
           M       0.47      0.76      0.58       387

    accuracy                           0.55      1045
   macro avg       0.56      0.54      0.49      1045
weighted avg       0.56      0.55      0.49      1045

(D) Accuracy: 0.5492822966507177
Macro Average F1 Score: 0.49030440123479974
Weighted Average F1 Score: 0.49324674377578775

------------------------------------------
Repeated Evaluation for MLPClassifier
Average Accuracy: 0.5427751196172249
Variance in Accuracy: 0.00019904306220095645
Average Macro F1 Score: 0.5166187971224289
Variance in Macro F1 Score: 0.0004840991700548332
Average Weighted F1 Score: 0.5171568123584068
Variance in Weighted F1 Score: 0.0005898387900647808

------------------------------------------
(A) Base-DT with default parameters
(B) Confusion Matrix:
[[117  50 143]
 [ 53 226  65]
 [146  71 174]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.37      0.38      0.37       310
           I       0.65      0.66      0.65       344
           M       0.46      0.45      0.45       391

    accuracy                           0.49      1045
   macro avg       0.49      0.49      0.49      1045
weighted avg       0.49      0.49      0.49      1045

(D) Accuracy: 0.49473684210526314
Macro Average F1 Score: 0.4927068078000922
Weighted Average F1 Score: 0.49466342658799506

------------------------------------------
(A) Top-DT with gridsearch
Parameters: criterion: [gini, entropy], max depth: [none, 10, 20], minimum sample split: [2, 4, 6]
Best parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 6}(B) Confusion Matrix:
[[114  52 144]
 [ 42 248  54]
 [172  79 140]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.35      0.37      0.36       310
           I       0.65      0.72      0.69       344
           M       0.41      0.36      0.38       391

    accuracy                           0.48      1045
   macro avg       0.47      0.48      0.48      1045
weighted avg       0.47      0.48      0.48      1045

(D) Accuracy: 0.48038277511961724
Macro Average F1 Score: 0.47582833047469714
Weighted Average F1 Score: 0.47555645266098184

------------------------------------------
Repeated Evaluation for DecisionTreeClassifier
Average Accuracy: 0.5198086124401914
Variance in Accuracy: 0.00014702960097067358
Average Macro F1 Score: 0.5172770200976402
Variance in Macro F1 Score: 0.0001939738190617813
Average Weighted F1 Score: 0.5158672035359031
Variance in Weighted F1 Score: 0.00021724419257433442

------------------------------------------
(A) Base-MLP with default parameters
(B) Confusion Matrix:
[[  3  50 257]
 [  0 243 101]
 [  3  71 317]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.01      0.02       310
           I       0.67      0.71      0.69       344
           M       0.47      0.81      0.59       391

    accuracy                           0.54      1045
   macro avg       0.55      0.51      0.43      1045
weighted avg       0.54      0.54      0.45      1045

(D) Accuracy: 0.538755980861244
Macro Average F1 Score: 0.4333915788120632
Weighted Average F1 Score: 0.4541317085154058

------------------------------------------
(A) Top-MLP with gridsearch
Parameters: activation function: [sigmoid, tanh, relu], hidden layers: [(30, 50), (10, 10, 10)], solver: [adam, sgd]
Best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}(B) Confusion Matrix:
[[110  39 161]
 [ 23 281  40]
 [141  80 170]]
(C) Classification Report:
              precision    recall  f1-score   support

           F       0.40      0.35      0.38       310
           I       0.70      0.82      0.76       344
           M       0.46      0.43      0.45       391

    accuracy                           0.54      1045
   macro avg       0.52      0.54      0.53      1045
weighted avg       0.52      0.54      0.53      1045

(D) Accuracy: 0.5368421052631579
Macro Average F1 Score: 0.5260942995249765
Weighted Average F1 Score: 0.5273609823355191

------------------------------------------
Repeated Evaluation for MLPClassifier
Average Accuracy: 0.5446889952153111
Variance in Accuracy: 0.0001331105057118657
Average Macro F1 Score: 0.5172234054682456
Variance in Macro F1 Score: 0.0002289285097362287
Average Weighted F1 Score: 0.5183713665617458
Variance in Weighted F1 Score: 0.00036927518392166063

